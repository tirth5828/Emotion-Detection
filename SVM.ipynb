{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04661911",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47063f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C:/Users/TIRTH JOSHI/Desktop/Sigmoid ML/dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82fb6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = pd.read_csv(\"C:/Users/TIRTH JOSHI/Desktop/Sigmoid ML/dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d8ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = train_data.columns.values[2:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a30cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text): \n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "def stem(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "en_stopwords = set(stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a97be78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(model, X, y):\n",
    "    pred = model.predict(X)        \n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec = recall_score(y, pred)\n",
    "    result = {'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "939d1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc__C = []\n",
    "for i in range(0,20,1):\n",
    "    svc__C.append(i/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e969e8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training anger\n",
      "dict_keys(['cv', 'error_score', 'estimator__memory', 'estimator__steps', 'estimator__verbose', 'estimator__countvectorizer', 'estimator__svc', 'estimator__countvectorizer__analyzer', 'estimator__countvectorizer__binary', 'estimator__countvectorizer__decode_error', 'estimator__countvectorizer__dtype', 'estimator__countvectorizer__encoding', 'estimator__countvectorizer__input', 'estimator__countvectorizer__lowercase', 'estimator__countvectorizer__max_df', 'estimator__countvectorizer__max_features', 'estimator__countvectorizer__min_df', 'estimator__countvectorizer__ngram_range', 'estimator__countvectorizer__preprocessor', 'estimator__countvectorizer__stop_words', 'estimator__countvectorizer__strip_accents', 'estimator__countvectorizer__token_pattern', 'estimator__countvectorizer__tokenizer', 'estimator__countvectorizer__vocabulary', 'estimator__svc__C', 'estimator__svc__break_ties', 'estimator__svc__cache_size', 'estimator__svc__class_weight', 'estimator__svc__coef0', 'estimator__svc__decision_function_shape', 'estimator__svc__degree', 'estimator__svc__gamma', 'estimator__svc__kernel', 'estimator__svc__max_iter', 'estimator__svc__probability', 'estimator__svc__random_state', 'estimator__svc__shrinking', 'estimator__svc__tol', 'estimator__svc__verbose', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter   for estimator Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'as', 'at', 'be',\n                                             'because', 'been', 'before',\n                                             'being', 'below', 'between',\n                                             'both', 'but', 'by', 'can',\n                                             'couldn', \"couldn't\", ...},\n                                 tokenizer=<function tokenize at 0x000001A16BCAF0D0>)),\n                ('svc', SVC(kernel='linear', probability=True))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 668, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 188, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 54, in _set_params\n    super().set_params(**params)\n  File \"C:\\Users\\TIRTH JOSHI\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 245, in set_params\n    raise ValueError(\nValueError: Invalid parameter   for estimator Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'as', 'at', 'be',\n                                             'because', 'been', 'before',\n                                             'being', 'below', 'between',\n                                             'both', 'but', 'by', 'can',\n                                             'couldn', \"couldn't\", ...},\n                                 tokenizer=<function tokenize at 0x000001A16BCAF0D0>)),\n                ('svc', SVC(kernel='linear', probability=True))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarted Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00memotion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_svm\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m---> 27\u001b[0m \u001b[43mgrid_svm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00memotion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00memotion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_svm\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter   for estimator Pipeline(steps=[('countvectorizer',\n                 CountVectorizer(stop_words={'a', 'about', 'above', 'after',\n                                             'again', 'against', 'ain', 'all',\n                                             'am', 'an', 'and', 'any', 'are',\n                                             'aren', \"aren't\", 'as', 'at', 'be',\n                                             'because', 'been', 'before',\n                                             'being', 'below', 'between',\n                                             'both', 'but', 'by', 'can',\n                                             'couldn', \"couldn't\", ...},\n                                 tokenizer=<function tokenize at 0x000001A16BCAF0D0>)),\n                ('svc', SVC(kernel='linear', probability=True))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "for emotion in emotions:\n",
    "    temp = train_data[[\"Tweet\" , emotion]]\n",
    "    emotion_data = temp.copy()\n",
    "    train, test = train_test_split(emotion_data, test_size=0.1, random_state=1)\n",
    "    X_train = train['Tweet'].values\n",
    "    X_test = test['Tweet'].values\n",
    "    y_train = train[emotion]\n",
    "    y_test = test[emotion]\n",
    "    vectorizer = CountVectorizer(\n",
    "        analyzer = 'word',\n",
    "        tokenizer = tokenize,\n",
    "        lowercase = True,\n",
    "        ngram_range=(1, 1),\n",
    "        stop_words = en_stopwords)\n",
    "    kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    np.random.seed(1)\n",
    "    pipeline_svm = make_pipeline(vectorizer, \n",
    "                            SVC(probability=True, kernel=\"linear\"))\n",
    "    grid_svm = GridSearchCV(pipeline_svm,\n",
    "                    param_grid = {' ': svc__C}, \n",
    "                    cv = kfolds,\n",
    "                    scoring=\"roc_auc\",\n",
    "                    verbose=1,   \n",
    "                    n_jobs=-1) \n",
    "    print(f\"Started Training {emotion}\")\n",
    "    print(grid_svm.get_params().keys())\n",
    "    grid_svm.fit(X_train, y_train)\n",
    "    print(f\"Completed Training {emotion}\")\n",
    "    print(f\"Score of {emotion} = {grid_svm.score(X_test, y_test)}\")\n",
    "    print(f\"grid_svm.best_params_ of {emotion} = {grid_svm.best_params_}\")\n",
    "    print(f\"grid_svm.best_score_ of {emotion} = {grid_svm.best_score_}\")\n",
    "    print(f\"For {emotion}\")\n",
    "    print(report_results(grid_svm.best_estimator_, X_test, y_test))\n",
    "    emotion_coloum = []\n",
    "    for tweet in output_data[\"Tweet\"]:\n",
    "        emotion_coloum.append(grid_svm.predict([tweet])[0])\n",
    "    output_data[emotion] = emotion_coloum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9edfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aefb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('C:/Users/TIRTH JOSHI/Desktop/Sigmoid ML/dataset/output.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "output_data.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/TIRTH JOSHI/Desktop/Sigmoid ML/dataset/output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fcdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = output_data[output_data.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f20147",
   "metadata": {},
   "outputs": [],
   "source": [
    "subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74384763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('C:/Users/TIRTH JOSHI/Desktop/Sigmoid ML/dataset/output.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "subm.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251488e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = data[[\"Tweet\" , \"anger\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73271f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anger_data = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anger_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(anger_data, test_size=0.2, random_state=1)\n",
    "# X_train = train['Tweet'].values\n",
    "# X_test = test['Tweet'].values\n",
    "# y_train = train['anger']\n",
    "# y_test = test['anger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f3e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(text): \n",
    "#     tknzr = TweetTokenizer()\n",
    "#     return tknzr.tokenize(text)\n",
    "\n",
    "# def stem(doc):\n",
    "#     return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "# en_stopwords = set(stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede85a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(\n",
    "#     analyzer = 'word',\n",
    "#     tokenizer = tokenize,\n",
    "#     lowercase = True,\n",
    "#     ngram_range=(1, 1),\n",
    "#     stop_words = en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfad1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca853c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_svm = make_pipeline(vectorizer, \n",
    "#                              SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65908354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_svm = GridSearchCV(pipeline_svm,\n",
    "#                     param_grid = {'svc__C': [0.01, 0.1, 1]}, \n",
    "#                     cv = kfolds,\n",
    "#                     scoring=\"roc_auc\",\n",
    "#                     verbose=1,   \n",
    "#                     n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc13914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_svm.fit(X_train, y_train)\n",
    "# grid_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0310d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def report_results(model, X, y):\n",
    "#     pred = model.predict(X)        \n",
    "#     acc = accuracy_score(y, pred)\n",
    "#     f1 = f1_score(y, pred)\n",
    "#     prec = precision_score(y, pred)\n",
    "#     rec = recall_score(y, pred)\n",
    "#     result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def report_results(model, X, y):\n",
    "#     pred_proba = model.predict_proba(X)[:, 1]\n",
    "#     pred = model.predict(X)        \n",
    "\n",
    "#     auc = roc_auc_score(y, pred_proba)\n",
    "#     acc = accuracy_score(y, pred)\n",
    "#     f1 = f1_score(y, pred)\n",
    "#     prec = precision_score(y, pred)\n",
    "#     rec = recall_score(y, pred)\n",
    "#     result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report_results(grid_svm.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36db08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078800f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
